## 1.4.4 Person independent KNN: 
Now try to apply k-nearest neighbor classification to the complete
data set from all students attending the course. Distinguish two cases: Having data from all individuals
in the training set and splitting the data according to individuals. Generate and explain the results.

For this part, we basically switched the previous code a little bit to have the different cases, so here are the raw code : 

* ### Individuals
````R
load("C:/Users/maxim/Documents/_SDU/_Statistical Machine Learning/Lecture 1/idList-co-100.Rdata")

# Individual
aList <- c(1:10)
for (i in c(1:10)) {
  id <- do.call(rbind, idList[i])
  id <- as.data.frame(id)
  id_shuffle <- id[sample(nrow(id)),]
  test_split <- id_shuffle[0:2000,-1]
  train_split <- id_shuffle[2001:4000,-1]
  
  test_classes <- id_shuffle[0:2000,1]
  train_classes <- id_shuffle[2001:4000,1]
  
  accuracy <- function(x){
    sum(diag(x)/(sum(rowSums(x)))) * 100
  }
  id_test_prediction <- knn(train_split, test_split, train_classes, k=23)
  confusion_matrix <- table(id_test_prediction, test_classes)
  acc = accuracy(confusion_matrix)
  aList[i] <- accuracy(confusion_matrix)
  
  cat("Folder :",i ," Accuracy:",acc, "\n")
}
aList
mean(aList)
var(aList)
````

* ### All persons in
````R
id <- do.call(rbind, idList[1:10])
dataset_shuffle <- id[sample(nrow(id)),]
test_split <- dataset_shuffle[0:2000,-1]
train_split <- dataset_shuffle[2001:4000,-1]
test_classes <- dataset_shuffle[0:2000,1]
train_classes <- dataset_shuffle[2001:4000,1]
ret <- run_knn(train_split, test_split, train_classes, k=3)
````

* ### Disjunct
````R
id_train <- do.call(rbind, idList[1:5])
id_train <- as.data.frame(id_train)
id_train$V1 <- factor(id_train$V1)
id_test <- do.call(rbind, idList[6:10])
id_test <- as.data.frame(id_test)
id_test$V1 <- factor(id_test$V1)

test_split <- id_test[0:2000,-1]
train_split <- id_train[0:2000,-1]
test_classes <- id_test[0:2000,1]
train_classes <- id_train[0:2000,1]
ret <- run_knn(train_split, test_split, train_classes, k=3)
````

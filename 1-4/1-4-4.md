## 1.4.4 Person independent KNN: 
Now try to apply k-nearest neighbor classification to the complete
data set from all students attending the course. Distinguish two cases: Having data from all individuals
in the training set and splitting the data according to individuals. Generate and explain the results.

For this part, we basically switched the previous code a little bit to have the different cases, so here are the raw code : 
````R
load("idList-co-100.Rdata")
````
* ### Individuals
````R
aList <- c(1:10)
for (i in c(1:10)) {
  id <- do.call(rbind, idList[i])
  id <- as.data.frame(id)
  id_shuffle <- id[sample(nrow(id)),]
  test_split <- id_shuffle[0:2000,-1]
  train_split <- id_shuffle[2001:4000,-1]
  
  test_classes <- id_shuffle[0:2000,1]
  train_classes <- id_shuffle[2001:4000,1]
  
  accuracy <- function(x){
    sum(diag(x)/(sum(rowSums(x)))) * 100
  }
  id_test_prediction <- knn(train_split, test_split, train_classes, k=3)
  confusion_matrix <- table(id_test_prediction, test_classes)
  acc = accuracy(confusion_matrix)
  aList[i] <- accuracy(confusion_matrix)
  
  cat("Folder :",i ," Accuracy:",acc, "\n")
}
aList
mean(aList)
var(aList)
````

* ### All persons in
````R
id <- do.call(rbind, idList[1:10])
dataset_shuffle <- id[sample(nrow(id)),]
test_split <- dataset_shuffle[0:2000,-1]
train_split <- dataset_shuffle[2001:4000,-1]
test_classes <- dataset_shuffle[0:2000,1]
train_classes <- dataset_shuffle[2001:4000,1]
ret <- run_knn(train_split, test_split, train_classes, k=3)
````

* ### Disjunct
````R
id_train <- do.call(rbind, idList[1:5])
id_train <- as.data.frame(id_train)
id_train$V1 <- factor(id_train$V1)
id_test <- do.call(rbind, idList[6:10])
id_test <- as.data.frame(id_test)
id_test$V1 <- factor(id_test$V1)

test_split <- id_test[0:2000,-1]
train_split <- id_train[0:2000,-1]
test_classes <- id_test[0:2000,1]
train_classes <- id_train[0:2000,1]
ret <- run_knn(train_split, test_split, train_classes, k=3)
````
First of all, if we run the three codes for a k of 3, we can directly see that the bigger the dataset the less accurate we are.
For instance, we have an accuracy of 98.535, 98.03 and 83.81 respectively for Individuals, In persons and Disjunct. 

For the first case, it is almost normal to have a better accuracy because the tested data will more likely be similar to the trained data since we are taking them from the same folder. So with more similarity between the two datasets it is then normal to be more accurate.

For the second case, we can see a small variation in the accuracy which is coming from the fact that we have a much bigger and diverse set of trained data so when we use it to compare it to our test data, it is normal to lose a bit of accuracy due to the diversity of the datas.

For the third and last case, obviously we are loosing a lot of accuracy because there can be a lot of unknow value in the tested data, so this is why we are loosing accuracy.

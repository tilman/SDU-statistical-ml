## 1-4-3 Cross validation
Perform a cross validation with a 90% / 10% split with 10 runs. Report mean and standard deviation of the performance. 

In this part, we have to do 10 runs with 90% of the data as the training data and 10% as the test data. We will split the data in 10 equal parts (10% each) and then do 10 runs with each of the splits as the test data.


We create the different 10% splits for the different runs
````R
accs <- c(1:10)
folds <- createFolds(id$X1, k=10)
````

We take each split as a training dataset and apply the same run_knn function (defined in 1-4-1) to each
````R
for (i in 1:10) {
  train_split <- id[-folds[[i]], -1]
  test_split <- id[folds[[i]],-1]
  train_classes <- id[-folds[[i]], 1]
  test_classes <- id[folds[[i]],1]
  
  ret <- run_knn(train_split, test_split, train_classes, k=3)
  accs[i] = ret$Accuracy
  runtimes[i] = ret$Runtime
}
````

This part shows the accuracy values and then, the mean and standard deviation of the performance
````R
print(runtimes)
print(accs)
mean(accs)
var(accs)
````

After running the algorithm, we get the following results :

* mean(accs) = 99.6
* var(accs) = 0.1

Therefore, the model is quite accurate, at least with k = 3.

With k = 15, it is less accurate : 
* mean(accs) = 99.325
* var(accs) = 0.2090278

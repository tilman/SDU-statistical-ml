## 1-4-3 Cross validation
### Perform a cross validation with a 90% / 10% split with 10 runs. Report mean and standard deviation of the performance. 


We create the different 10% splits for the different runs
````R
listOfFolders <- c(1:10)
folds <- createFolds(id$X1, k=10)
````

We take each split as a training dataset and apply the same knn function to each
````R
for (i in 1:10) {
  id_train <- id[-folds[[i]], -1]
  id_test <- id[folds[[i]],-1]
  id_train_labels <- id[-folds[[i]], 1]
  id_test_labels <- id[folds[[i]],1]
  predictions <- knn(id_train, id_test, id_train_labels,k=7)
  cm <- confusionMatrix(id_test_labels, predictions)
  # Here, we put each accuracy value in the list we created before
  listOfFolders[i] <- sum(diag(cm$table))/sum(cm$table)*100
}
````

This part shows the accuracy values and then, the mean and standard deviation of the performance
````R
listOfFolders
mean(listOfFolders)
var(listOfFolders)
````


# 1.4 Performing K-nearest neighbor ( Report 1 )
## 1.4.1 K-Nearest Neighbour:
Using the methods learned in the Chapter 3 in “Machine Learning With R”, KNN can now be performed on our own generated dataset. 
First we will test on a single person. 
Remember to split between training and test set (split in two equally sized parts).

### Document the results:

````R
load("~/Downloads/id100.rda")
dataset_shuffle <- id[sample(nrow(id)),]
test_split <- dataset_shuffle[0:2000,-1]
train_split <- dataset_shuffle[2001:4000,-1]
test_classes <- dataset_shuffle[0:2000,1]
train_classes <- dataset_shuffle[2001:4000,1]
````
First we load the dataset id100. It contains only the data from one person, all datapoints are ordered after the number so it's really important to shuffle the dataset first, before cutting the test and train split out of it.

````R
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
run_knn <- function(train_split, test_split, train_classes, k){
  start_time <- Sys.time()
  test_prediction <- knn(train_split,test_split,cl=train_classes,k)
  end_time <- Sys.time()
  confusion_matrix <- table(test_prediction, test_classes)
  runtime = end_time - start_time
  acc = accuracy(confusion_matrix)
  cat("K:",k," Accuracy:",acc," Runtime:",runtime, "\n")
  df <- list(K=k,Accuracy=acc,Runtime=runtime)
  return(df)
}
````
We wrapped the whole time measurment and accuracy calculation in one function called `run_knn`, to reduce code and have a consistent measurement over all exercises. For time measurement we take the difference of the timestamps before and after knn run. The result of the knn method is a list of labels in the same order as our provided test split. We would have an ideal prediction if the lists `test_prediction` and `test_classes` are equal. Because in reality they are not equal we need a way to measure this. For the accuracy calculation we build the confusion matrix. The confusion matrix will give us counts how many of the labels are actually predicted the right way. One axis is the label and the other one the actuall prediction.
````bash
               test_classes
test_prediction   0   1   2   3   4   5   6   7   8   9
              0 201   0   0   1   0   0   0   0   1   0
              1   0 213   0   1   0   0   0   0   0   0
              2   0   0 189   1   0   0   0   0   2   0
              3   0   0   0 193   0   0   0   0   1   0
              4   0   0   0   0 191   0   0   0   0   0
              5   0   0   0   0   0 204   0   0   2   0
              6   0   0   0   0   0   0 199   0   0   0
              7   0   0   0   1   0   0   0 184   0   0
              8   0   0   1   0   0   1   0   0 197   0
              9   0   0   0   0   0   0   0   1   0 216
````
Therefore a perfect prediction would only have values on the diagonal. In the above confusion matrix we can see, for example that we have `1` Number with Label `2` accidently classified as an `8`.

* Can you explain the performance (computation time and test accuracy) on the training and test-set?

````R
test_classes <- id_test[0:2000,1]
train_classes <- id_train[0:2000,1]
````
